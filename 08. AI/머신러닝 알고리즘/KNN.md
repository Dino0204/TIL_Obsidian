![[Pasted image 20250525114129.png]]

K Nearest Neighbors
데이터를 거리를 기반으로 예측하는 [[분류]] 모델

## 특징
---
데이터 간의 거리를 활용하여 새로운 데이터를 예측하는 모델
가장 가까운 데이터를 고려하여 예측 값이 결정된다.

## 장단점
---
### 장점
비교적 간단한 알고리즘이다.
선형 모델과 다르게 별도의 가정이 필요 없다.

### 단점
데이터가 커질수록 상당히 느려진다.
아웃라이너에 취약하다.

## 예시
---
### 와인 등급 분류
예를 들어 와인의 성분들의 값을 기반으로 와인 등급을 분류할 때 어떤 성분이 영향이 클까?

### 전처리
1. 고유값 개수 확인: dummy 변수로 변환 가능한지 판단한다.
2. dummy 변수로 범위 스케일링: KNN은 거리 기반 알고리즘이기 때문에 각 column이 비슷한 범위를 가지도록 한다.
	1. Standard: 평균 = 0, 표준편차 = 1이 되도록 데이터를 고르게 분포시키는 표준화 기법이다.
	2. MinMax: 원래 데이터의 분포를 유지하고 싶을 때 최소값 = 0, 최대값 = 1이 되도록 범위를 맞춰주는 기법이다.
	3. Robust: 데이터의 outliner가 있을 경우 영향력을 줄이기 위해 중위수를 이용하는 기법이다.
	4. Normalizer: Standard와 비슷한 정규화 기법이다.

### 모델링 예측 및 평가
1. train, test data set 나누기
2. KNN 모델에 학습시키기
3. 학습한 모델의 정확도 분석하기
4. 하이퍼 파라미터 튜닝하기: K(이웃의 수)의 수에 따라 모델의 정확도가 나뉘기 때문에 정확도가 높으며 복잡성이 낮은 이웃의 수를 도출한다.

## 사용하는 경우
---
주로 분류에서 사용되며 작은 데이터 셋을 처리 할 때 사용한다.

